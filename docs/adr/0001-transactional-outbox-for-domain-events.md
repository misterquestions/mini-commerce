# ADR 0001: Adopt Transactional Outbox for Critical Domain Events

Date: 2025-09-09
Status: Accepted

## Context
Currently the order-service publishes Kafka events (order.created, order.cancelled) via a transaction `afterCommit` callback. If Kafka is unavailable at commit time, the event can be lost silently (even if logged). We need durability, replay capability, and controlled retries for cross-service consistency (payments, inventory, fulfillment, analytics).

## Decision
Implement a Transactional Outbox pattern for the order-service (and later other producers) where domain state changes and an outbox record are persisted atomically. A relay component (initially scheduled poller, optionally replaced by CDC) publishes events to Kafka with idempotent producer configuration and updates outbox status (NEW -> SENT / RETRY / FAILED).

## Rationale
- Guarantees no event loss once DB commit succeeds.
- Decouples user-facing request latency from broker availability.
- Enables replay / dead-letter handling through FAILED state.
- Simpler operational model than XA or dual-phase commit.

Alternatives Considered:
1. Kafka Transactions (DB + Kafka dual write): Higher complexity; still need retry story; tight coupling.
2. Best-effort afterCommit (current): Risk of silent loss under outage; no replay.
3. Debezium CDC Outbox only (skip app relay): Adds infra overhead now; adopt later after pattern stabilizes.

## Consequences
Positive:
- Increased reliability / auditability.
- Observable backlog (metric) enabling proactive alerting.
Negative / Risks:
- Additional table + relay component maintenance.
- Potential backlog growth under sustained Kafka outage (requires alert & ops playbook).

Mitigations:
- Metrics: outbox_pending, outbox_failed, oldest_outbox_age.
- Backoff + max attempts -> FAILED with alert.
- Admin/CLI to requeue FAILED rows (status -> NEW).

## Implementation Notes
Phase 1 (order-service):
1. Add `outbox_events` table: id (UUID), aggregate_id, topic, key, payload JSONB, status (NEW|SENT|RETRY|FAILED), attempts, next_attempt_at, created_at, updated_at, last_error.
2. Replace direct `events.publish` calls with insertion of outbox row in same transaction.
3. Add scheduled relay (@Scheduled fixedDelay=500ms) using `SELECT ... FOR UPDATE SKIP LOCKED` to fetch batch (e.g., 50) NEW/RETRY rows due.
4. Publish each with KafkaTemplate (acks=all, idempotence). On success -> SENT; on failure -> attempts++, compute backoff, status=RETRY or FAILED after maxAttempts.
5. Metrics + structured logs for each transition.
6. Tests: simulate transient failure -> row transitions NEW -> RETRY -> SENT; simulate permanent -> FAILED.

Phase 2:
- Introduce Debezium Outbox connector (optional) to replace poller.
- Standardize EventEnvelope schema (eventId, type, version, occurredAt, traceId, data).

## Diagram

![Transactional Outbox Flow](../diagrams/outbox-flow.puml)

This diagram illustrates the atomic commit of domain changes and outbox event, followed by asynchronous relay to Kafka. For more, see [Order Service README](../../order-service/README.md).

## References
- Microservices Patterns (Richardson) â€“ Transactional Outbox.
- Kafka Idempotent Producer docs.
- Internal issue: OUTBOX-1.
